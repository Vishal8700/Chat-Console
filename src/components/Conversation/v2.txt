// import React, { useState, useRef, useEffect, useCallback } from 'react';
// import './VoiceConversation.css';

// const VoiceConversation = () => {
//   const [isListening, setIsListening] = useState(false);
//   const [isProcessing, setIsProcessing] = useState(false);
//   const [isSpeaking, setIsSpeaking] = useState(false);
//   const [transcript, setTranscript] = useState('');
//   const [conversation, setConversation] = useState([]);
//   const [audioLevel, setAudioLevel] = useState(0);
//   const [error, setError] = useState(null);
//   const [particles, setParticles] = useState([]);

//   const recognition = useRef(null);
//   const audioContextRef = useRef(null);
//   const analyserRef = useRef(null);
//   const animationFrameRef = useRef(null);
//   const micStreamRef = useRef(null);
//   const speechSynthesisRef = useRef(null);
//   const isCleaningUpRef = useRef(false);

//   // Generate particles for visual effect
//   useEffect(() => {
//     const generateParticles = () => {
//       const newParticles = [];
//       for (let i = 0; i < 50; i++) {
//         const angle = (i / 50) * 2 * Math.PI;
//         const radius = 120 + Math.random() * 30;
//         newParticles.push({
//           id: i,
//           x: Math.cos(angle) * radius,
//           y: Math.sin(angle) * radius,
//           baseX: Math.cos(angle) * radius,
//           baseY: Math.sin(angle) * radius,
//           angle: angle
//         });
//       }
//       setParticles(newParticles);
//     };
//     generateParticles();
//   }, []);

//   // Animate particles based on audio level
//   useEffect(() => {
//     if (isListening && audioLevel > 0) {
//       setParticles(prevParticles => 
//         prevParticles.map(particle => ({
//           ...particle,
//           x: particle.baseX + (Math.random() - 0.5) * audioLevel * 2,
//           y: particle.baseY + (Math.random() - 0.5) * audioLevel * 2
//         }))
//       );
//     }
//   }, [audioLevel, isListening]);

//   // Cleanup function
//   const cleanup = useCallback(() => {
//     if (isCleaningUpRef.current) return;
//     isCleaningUpRef.current = true;

//     console.log('Cleaning up voice conversation...');

//     // Stop speech recognition
//     if (recognition.current) {
//       try {
//         recognition.current.stop();
//         recognition.current.abort();
//       } catch (e) {
//         console.warn('Error stopping recognition:', e);
//       }
//     }

//     // Stop speech synthesis
//     if (speechSynthesisRef.current || window.speechSynthesis) {
//       try {
//         window.speechSynthesis.cancel();
//       } catch (e) {
//         console.warn('Error stopping speech synthesis:', e);
//       }
//     }

//     // Stop audio monitoring
//     if (animationFrameRef.current) {
//       cancelAnimationFrame(animationFrameRef.current);
//       animationFrameRef.current = null;
//     }

//     if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
//       try {
//         audioContextRef.current.close();
//       } catch (e) {
//         console.warn('Error closing audio context:', e);
//       }
//       audioContextRef.current = null;
//     }

//     // Stop microphone stream
//     if (micStreamRef.current) {
//       try {
//         micStreamRef.current.getTracks().forEach(track => {
//           if (track.readyState === 'live') {
//             track.stop();
//           }
//         });
//       } catch (e) {
//         console.warn('Error stopping mic stream:', e);
//       }
//       micStreamRef.current = null;
//     }

//     // Reset states
//     setIsListening(false);
//     setIsSpeaking(false);
//     setAudioLevel(0);
    
//     isCleaningUpRef.current = false;
//   }, []);

//   // Handle send message
//   const handleSendMessage = useCallback(async (message) => {
//     console.log('Processing message:', message);
//     setIsProcessing(true);
//     setError(null);
    
//     try {
//       // Add user's message to conversation
//       const userMessage = { role: 'user', content: message };
//       setConversation(prev => [...prev, userMessage]);
      
//       // Get stored conversation history
//       let storedConversation = [];
//       try {
//         const stored = localStorage.getItem('voiceConversation');
//         storedConversation = stored ? JSON.parse(stored) : [];
//       } catch (e) {
//         console.warn('Error reading localStorage:', e);
//         storedConversation = [];
//       }
      
//       // Build full conversation context
//       const fullConversation = [...storedConversation, userMessage];
      
//       console.log('Calling Gemini API...');
//       // Get response from Gemini
//       const response = await callGeminiAPI(fullConversation);
//       console.log('Gemini response:', response);
      
//       // Add assistant's response to conversation
//       const assistantMessage = { role: 'assistant', content: response };
//       const updatedConversation = [...fullConversation, assistantMessage];
      
//       // Update state and localStorage
//       setConversation(updatedConversation);
//       try {
//         localStorage.setItem('voiceConversation', JSON.stringify(updatedConversation));
//       } catch (e) {
//         console.warn('Error saving to localStorage:', e);
//       }
      
//       console.log('Speaking response...');
//       // Convert response to speech
//       await speakText(response);
//       console.log('Speech completed');
      
//     } catch (error) {
//       console.error('Error processing message:', error);
//       setError(`Error: ${error.message}`);
//       const errorMessage = 'Sorry, I encountered an error processing your request.';
//       try {
//         await speakText(errorMessage);
//       } catch (speechError) {
//         console.error('Error speaking error message:', speechError);
//       }
//     } finally {
//       setIsProcessing(false);
//     }
//   }, []);

//   // Initialize speech recognition
//   useEffect(() => {
//     if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
//       setError('Speech recognition is not supported in this browser');
//       return;
//     }

//     const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
//     recognition.current = new SpeechRecognition();
//     recognition.current.continuous = false;
//     recognition.current.interimResults = true;
//     recognition.current.lang = 'en-US';
//     recognition.current.maxAlternatives = 1;

//     recognition.current.onresult = (event) => {
//       let finalTranscript = '';
//       let interimTranscript = '';
      
//       for (let i = event.resultIndex; i < event.results.length; i++) {
//         if (event.results[i].isFinal) {
//           finalTranscript += event.results[i][0].transcript;
//         } else {
//           interimTranscript += event.results[i][0].transcript;
//         }
//       }
      
//       // Update transcript display
//       setTranscript(interimTranscript || finalTranscript);
      
//       if (finalTranscript.trim()) {
//         console.log('Final transcript:', finalTranscript);
//         handleSendMessage(finalTranscript.trim());
//       }
//     };

//     recognition.current.onerror = (event) => {
//       console.error('Speech recognition error:', event.error);
//       setError(`Speech recognition error: ${event.error}`);
//       setIsListening(false);
//       setTranscript('');
//     };

//     recognition.current.onend = () => {
//       console.log('Speech recognition ended');
//       setIsListening(false);
//       setTranscript('');
//     };

//     recognition.current.onstart = () => {
//       console.log('Speech recognition started');
//       setError(null);
//     };

//     return cleanup;
//   }, [cleanup, handleSendMessage]);

//   // Handle page unload/refresh
//   useEffect(() => {
//     const handleBeforeUnload = () => {
//       cleanup();
//     };

//     const handleVisibilityChange = () => {
//       if (document.hidden) {
//         cleanup();
//       }
//     };

//     window.addEventListener('beforeunload', handleBeforeUnload);
//     document.addEventListener('visibilitychange', handleVisibilityChange);

//     return () => {
//       window.removeEventListener('beforeunload', handleBeforeUnload);
//       document.removeEventListener('visibilitychange', handleVisibilityChange);
//       cleanup();
//     };
//   }, [cleanup]);

//   const startAudioMonitoring = async () => {
//     try {
//       const stream = await navigator.mediaDevices.getUserMedia({ 
//         audio: {
//           echoCancellation: true,
//           noiseSuppression: true,
//           autoGainControl: true
//         } 
//       });
      
//       micStreamRef.current = stream;
//       audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
//       analyserRef.current = audioContextRef.current.createAnalyser();
//       const source = audioContextRef.current.createMediaStreamSource(stream);
//       source.connect(analyserRef.current);

//       analyserRef.current.fftSize = 256;
//       const bufferLength = analyserRef.current.frequencyBinCount;
//       const dataArray = new Uint8Array(bufferLength);

//       const updateAudioLevel = () => {
//         if (!analyserRef.current || isCleaningUpRef.current) return;
        
//         analyserRef.current.getByteFrequencyData(dataArray);
//         const average = dataArray.reduce((a, b) => a + b) / bufferLength;
//         setAudioLevel(Math.min(average / 2, 100));
//         animationFrameRef.current = requestAnimationFrame(updateAudioLevel);
//       };

//       updateAudioLevel();
//     } catch (error) {
//       console.error('Error accessing microphone:', error);
//       setError('Could not access microphone. Please check permissions.');
//     }
//   };

//   const stopAudioMonitoring = () => {
//     if (animationFrameRef.current) {
//       cancelAnimationFrame(animationFrameRef.current);
//       animationFrameRef.current = null;
//     }

//     if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
//       try {
//         audioContextRef.current.close();
//       } catch (e) {
//         console.warn('Error closing audio context:', e);
//       }
//       audioContextRef.current = null;
//     }

//     if (micStreamRef.current) {
//       try {
//         micStreamRef.current.getTracks().forEach(track => {
//           if (track.readyState === 'live') {
//             track.stop();
//           }
//         });
//       } catch (e) {
//         console.warn('Error stopping mic stream:', e);
//       }
//       micStreamRef.current = null;
//     }

//     setAudioLevel(0);
//   };

//   const startListening = async () => {
//     if (!recognition.current || isListening || isProcessing || isSpeaking) {
//       console.log('Cannot start listening:', { isListening, isProcessing, isSpeaking });
//       return;
//     }

//     try {
//       console.log('Starting to listen...');
//       setIsListening(true);
//       setTranscript('');
//       setError(null);
      
//       await startAudioMonitoring();
//       recognition.current.start();
//     } catch (error) {
//       console.error('Error starting listening:', error);
//       setError('Failed to start listening');
//       setIsListening(false);
//     }
//   };

//   const stopListening = () => {
//     console.log('Stopping listening...');
//     if (recognition.current && isListening) {
//       try {
//         recognition.current.stop();
//       } catch (e) {
//         console.warn('Error stopping recognition:', e);
//       }
//       stopAudioMonitoring();
//       setIsListening(false);
//       setTranscript('');
//     }
//   };

//   const speakText = (text) => {
//     return new Promise((resolve, reject) => {
//       console.log('Starting speech synthesis for:', text);
      
//       if (!window.speechSynthesis) {
//         console.error('Speech synthesis not supported');
//         reject(new Error('Speech synthesis not supported'));
//         return;
//       }

//       // Stop listening before speaking
//       if (isListening) {
//         stopListening();
//       }

//       // Cancel any ongoing speech
//       window.speechSynthesis.cancel();

//       // Wait a bit for cancellation to complete
//       setTimeout(() => {
//         const utterance = new SpeechSynthesisUtterance(text);
//         utterance.rate = 0.9;
//         utterance.pitch = 1.0;
//         utterance.volume = 1.0;

//         utterance.onstart = () => {
//           console.log('Speech started');
//           setIsSpeaking(true);
//         };

//         utterance.onend = () => {
//           console.log('Speech ended');
//           setIsSpeaking(false);
//           speechSynthesisRef.current = null;

//           // Automatically start listening again after a short delay
//           if (!isCleaningUpRef.current && !isProcessing) {
//             console.log('Scheduling listening restart...');
//             setTimeout(() => {
//               if (!isCleaningUpRef.current && !isSpeaking && !isProcessing) {
//                 console.log('Automatically restarting listening...');
//                 startListening();
//               }
//             }, 500); // 500ms delay for natural flow
//           }
//           resolve();
//         };

//         utterance.onerror = (event) => {
//           console.error('Speech synthesis error:', event.error);
//           setIsSpeaking(false);
//           speechSynthesisRef.current = null;
//           reject(new Error(`Speech synthesis error: ${event.error}`));
//         };

//         speechSynthesisRef.current = utterance;
        
//         // Ensure voices are loaded before speaking
//         if (window.speechSynthesis.getVoices().length === 0) {
//           window.speechSynthesis.addEventListener('voiceschanged', () => {
//             window.speechSynthesis.speak(utterance);
//           }, { once: true });
//         } else {
//           window.speechSynthesis.speak(utterance);
//         }
//       }, 100);
//     });
//   };

//   const callGeminiAPI = async (messages) => {
//     const GEMINI_API_KEY = import.meta.env.VITE_GEMINI_API_KEY || 'AIzaSyBfM1Kde7RfKMVNlppA0i6SoPA8cJzFuB8';
//     const MAX_RETRIES = 3;
//     let retries = 0;

//     while (retries < MAX_RETRIES) {
//       try {
//         const prompt = messages.map(msg => `${msg.role}: ${msg.content}`).join('\n');
//         console.log('Sending to Gemini:', prompt);
        
//         const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${GEMINI_API_KEY}`, {
//           method: 'POST',
//           headers: {
//             'Content-Type': 'application/json',
//           },
//           body: JSON.stringify({
//             contents: [{
//               parts: [{
//                 text: prompt + '\n\nPlease provide a brief, conversational response suitable for voice interaction.'
//               }]
//             }],
//             generationConfig: {
//               temperature: 0.7,
//               topK: 40,
//               topP: 0.95,
//               maxOutputTokens: 150, // Shorter responses for voice
//             },
//             safetySettings: [
//               {
//                 category: "HARM_CATEGORY_HARASSMENT",
//                 threshold: "BLOCK_MEDIUM_AND_ABOVE"
//               },
//               {
//                 category: "HARM_CATEGORY_HATE_SPEECH",
//                 threshold: "BLOCK_MEDIUM_AND_ABOVE"
//               },
//               {
//                 category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
//                 threshold: "BLOCK_MEDIUM_AND_ABOVE"
//               },
//               {
//                 category: "HARM_CATEGORY_DANGEROUS_CONTENT",
//                 threshold: "BLOCK_MEDIUM_AND_ABOVE"
//               }
//             ]
//           })
//         });

//         if (!response.ok) {
//           const errorText = await response.text();
//           console.error('Gemini API error:', response.status, errorText);
          
//           if (response.status === 503 || response.status === 429) {
//             retries++;
//             if (retries < MAX_RETRIES) {
//               console.log(`Retrying in ${1000 * retries}ms...`);
//               await new Promise(resolve => setTimeout(resolve, 1000 * retries));
//               continue;
//             }
//           }
//           throw new Error(`Gemini API error: ${response.status} ${response.statusText}`);
//         }

//         const data = await response.json();
//         console.log('Gemini API response:', data);
        
//         const responseText = data.candidates?.[0]?.content?.parts?.[0]?.text;
//         if (!responseText) {
//           throw new Error('No response text received from Gemini');
//         }
        
//         return responseText.trim();
//       } catch (error) {
//         console.error(`Attempt ${retries + 1} failed:`, error);
//         if (retries === MAX_RETRIES - 1) {
//           throw error;
//         }
//         retries++;
//         await new Promise(resolve => setTimeout(resolve, 1000 * retries));
//       }
//     }
//   };

//   const clearConversation = () => {
//     cleanup();
//     setConversation([]);
//     setError(null);
//     try {
//       localStorage.removeItem('voiceConversation');
//     } catch (e) {
//       console.warn('Error clearing localStorage:', e);
//     }
//   };

//   const getStatusText = () => {
//     if (error) return error;
//     if (isProcessing) return 'Processing...';
//     if (isSpeaking) return 'Speaking...';
//     if (isListening) return 'Listening...';
//     return 'Tap to speak';
//   };

//   const getParticleClassName = () => {
//     if (isSpeaking) return 'speaking';
//     if (isProcessing) return 'processing';
//     if (isListening) return 'listening';
//     return '';
//   };

//   return (
//     <div className="voice-conversation">
     
    

//       {/* Conversation area */}
//       {/* <div className="conversation-area">
//         <div className="messages">
//           {conversation.map((message, index) => (
//             <div key={index} className={`message ${message.role}`}>
//               <strong>{message.role === 'user' ? 'You' : 'Assistant'}</strong>
//               <p>{message.content}</p>
//             </div>
//           ))}
//         </div>
//       </div> */}

//       {/* Voice interface */}
//       <div className="voice-interface">
//         {/* Particle animation */}
//         <div className="particle-container">
//           <div className={`particle-circle ${getParticleClassName()}`}>
//             {particles.map(particle => (
//               <div
//                 key={particle.id}
//                 className="particle"
//                 style={{
//                   left: `calc(50% + ${particle.x}px)`,
//                   top: `calc(50% + ${particle.y}px)`
//                 }}
//               />
//             ))}
//           </div>
//         </div>

//         {/* Controls */}
//         <div className="controls">
//         <button
//             onClick={isListening ? stopListening : startListening}
//             disabled={isProcessing}
//             className={`voice-button ${isListening ? 'listening' : ''}`}
//           >
//             {isListening ? (
//               // Pause SVG
//               <svg width="24" height="24" viewBox="0 0 24 24" fill="none">
//                 <rect x="6" y="4" width="4" height="16" fill="#333"/>
//                 <rect x="14" y="4" width="4" height="16" fill="#333"/>
//               </svg>
//             ) : (
//               // Microphone SVG
//               <svg width="24" height="24" viewBox="0 0 24 24" fill="none">
//                 <rect x="9" y="3" width="6" height="12" rx="3" fill="#333"/>
//                 <path d="M5 10v2a7 7 0 0 0 14 0v-2" stroke="#333" strokeWidth="2"/>
//                 <line x1="12" y1="19" x2="12" y2="22" stroke="#333" strokeWidth="2"/>
//                 <line x1="8" y1="22" x2="16" y2="22" stroke="#333" strokeWidth="2"/>
//               </svg>
//             )}
//           </button>


//           {/* {(isListening || isProcessing || isSpeaking) && (
//             <button
//               onClick={cleanup}
//               className="stop-button"
//             >
//               ⏹️
//             </button>
//           )} */}
//           <button onClick={clearConversation} className="clear-button-round" title="Clear Conversation">
//   <svg
//     width="22"
//     height="22"
//     viewBox="0 0 24 24"
//     fill="none"
//     xmlns="http://www.w3.org/2000/svg"
//     style={{ display: 'block', margin: 'auto' }}
//   >
//     <path
//       d="M3 6h18M8 6v12a2 2 0 0 0 2 2h4a2 2 0 0 0 2-2V6m-6 0V4a2 2 0 0 1 2-2h0a2 2 0 0 1 2 2v2"
//       stroke="#e53935"
//       strokeWidth="2"
//       strokeLinecap="round"
//       strokeLinejoin="round"
//     />
//     <line x1="10" y1="11" x2="10" y2="17" stroke="#e53935" strokeWidth="2" />
//     <line x1="14" y1="11" x2="14" y2="17" stroke="#e53935" strokeWidth="2" />
//   </svg>
// </button>


//         </div>

//         {/* Status display */}
//         <div className="status">
//           <div className="status-text">{getStatusText()}</div>
//           {transcript && (
//             <div className="transcript">"{transcript}"</div>
//           )}
//         </div>
//       </div>
//     </div>
//   );
// };

// export default VoiceConversation;